{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 음향 모델\n",
    "\n",
    "음성인식에서 음성 데이터의 특징을 추출하는 데 사용되는 모델\n",
    "음성 데이터를 시간에 따라 숨겨진 상태로 모델링하고, 이 상태를 사용하여 음성의 특징 추출\n",
    "\n",
    "음향 모델 구성 요소\n",
    "\n",
    "초기 상태 분포 - 음성 인식 시작 부분에서 음성 상태가 어떤 것일지 확률적으로 나타내는 분포\n",
    "\n",
    "상태 전이 확률 - 한 상태에서 다음 상태로 전이할 확률을 나타내는 행렬\n",
    "\n",
    "관측 확률  - 각 상태에서 관측될 수 있는 음성 신호의 확률을 나타내는 행렬\n",
    "\n",
    "\n",
    "음향 모델 종류\n",
    "HMM( Hidden Markov Model )\n",
    "GMM( Gaussian Mixture Model )\n",
    "GMM-HMM\n",
    "DNN-HMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#HMM(Hidden Markov Model)\n",
    "\n",
    "HMM은 Markov Chain을  전제로 한 모델\n",
    "\n",
    "Markov Chain\n",
    "    마코프 성질을 가진 이산 확률 과정\n",
    "    마코프 성질 - 한 상태(state) qi가 나타날 확률은 단지 이전 상태 qi-q에만 의존한다.\n",
    "        한 상태에서 다른 상태로의 전이는 그동안 상태 전이에 대한 긴이력을 필요로 하지 않고 바로 직전 상태로의 전이로 추정할 수 있다.\n",
    "    \n",
    "    마코프 체인은 시간 변화에 따른 상태들의 분포 추적에 관심을 갖는다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM\n",
    "\n",
    "우도 계산의 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import random\n",
    "\n",
    "import IPython.display as idp\n",
    "\n",
    "# 푸리에 변환을 위한 라이브러리\n",
    "import math\n",
    "from scipy.interpolate import splrep, splev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Fair', 'Loaded'] # 은닉상태\n",
    "ovservations = [1,2,3,4,5,6] # 관측치 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전이 확률 \n",
    "transitions ={\n",
    "    'Fair': {'Fair' : 0.95, 'Loaded':0.055},\n",
    "    'Loaded': {\"Fair\":0.10,'Loaded':0.90}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#방출확률\n",
    "emissions = {\n",
    "    'Fair': {1: 1/6, 2: 1/6, 3: 1/6, 4 : 1/6, 5 :1/6, 6: 1/6},\n",
    "    'Loaded' : {1: 1/10, 2: 1/10, 3: 1/10, 4: 1/10, 5: 1/10, 6: 5/10}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태 분포\n",
    "initial_probs = {'Fair': 0.5, 'Loaded':0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#관측 순서\n",
    "observed_sequence = [3,5,2,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fair', 'Loaded']\n",
      "Likelihood: 9.730013278034976e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "states = ['Fair', 'Loaded']  # 은닉상태\n",
    "observations = [1, 2, 3, 4, 5, 6]  # 관측치\n",
    "\n",
    "transitions = {\n",
    "    'Fair': {'Fair': 0.95, 'Loaded': 0.055},\n",
    "    'Loaded': {'Fair': 0.10, 'Loaded': 0.90}\n",
    "}\n",
    "\n",
    "# 방출확률\n",
    "emissions = {\n",
    "    'Fair': {1: 1/6, 2: 1/6, 3: 1/6, 4: 1/6, 5: 1/6, 6: 1/6},\n",
    "    'Loaded': {1: 1/10, 2: 1/10, 3: 1/10, 4: 1/10, 5: 1/10, 6: 5/10}\n",
    "}\n",
    "\n",
    "# 초기 상태 분포\n",
    "initial_probs = {'Fair': 0.5, 'Loaded': 0.5}\n",
    "\n",
    "# 관측 순서\n",
    "observed_sequence = [3, 5, 2, 4, 6]\n",
    "\n",
    "# 우도 계산 (Forward Algorithm 사용)\n",
    "def compute_likelihood(sequence):\n",
    "    print(states)\n",
    "    n_states = len(states)\n",
    "    n_obs = len(sequence)\n",
    "\n",
    "    alpha = np.zeros((n_obs, n_states))\n",
    "    for i, obs in enumerate(sequence):\n",
    "        for j, state in enumerate(states):\n",
    "            if i == 0:\n",
    "                alpha[i, j] = initial_probs[state] * emissions[state][obs]\n",
    "            else:\n",
    "                alpha[i, j] = sum(alpha[i-1, k] * transitions[states[k]][state] * emissions[state][obs] for k in range(n_states))\n",
    "\n",
    "    likelihood = np.sum(alpha[-1])\n",
    "\n",
    "    return likelihood\n",
    "\n",
    "likelihood = compute_likelihood(observed_sequence)\n",
    "\n",
    "print(f'Likelihood: {likelihood}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'states' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m likelihood \u001b[39m=\u001b[39m compute_likelihood(observed_sequence)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLikelihood: \u001b[39m\u001b[39m{\u001b[39;00mlikelihood\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m, in \u001b[0;36mcompute_likelihood\u001b[1;34m(sequence)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_likelihood\u001b[39m(sequence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[39mprint\u001b[39m(states)\n\u001b[0;32m      4\u001b[0m     n_states \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(states)\n\u001b[0;32m      5\u001b[0m     n_obs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(sequence)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'states' referenced before assignment"
     ]
    }
   ],
   "source": [
    "likelihood = compute_likelihood(observed_sequence)\n",
    "\n",
    "print(f'Likelihood: {likelihood}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foward Algorithm/ Backward Algorithm 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_states = ['hot', 'cold']#은닉 상태\n",
    "symbols = ['1', '2', '3'] #관측치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전이확률\n",
    "trans_prob = {\n",
    "    'hot': { 'hot' : 0.6, 'cold' : 0.4 },\n",
    "    'cold': { 'hot' : 0.4, 'cold' : 0.6 }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방출확률\n",
    "emit_prob = {\n",
    "    'hot': { '1' : 0.2, '2' : 0.4, '3' : 0.4 },\n",
    "    'cold': { '1' : 0.5, '2' : 0.4, '3' : 0.1 }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#초기 상태 분포\n",
    "start_prob = {\n",
    "    'hot' : 0.8,\n",
    "    'cold' : 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관측 순서\n",
    "sequence = ['3', '1', '3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _forward(sequence):\n",
    "    # sequence : O\n",
    "    # 아이스크림 소비 기록 시퀀스 [3, 1, 3]\n",
    "    sequence_length = len(sequence)\n",
    "    if sequence_length == 0:\n",
    "        return []\n",
    "    \n",
    "    # Dynamic Programming\n",
    "    # 앞으로 중간 계산된 값들은 alpha라는 변수에 저장\n",
    "    alpha = [{}]\n",
    "    \n",
    "    # 시작 지점의 alpha값 계산 후 alpha[0]에 저장\n",
    "    # alpha[0] = {'hot' : p(hot\\|start) * p(3\\|hot), \n",
    "    #             'cold' : p(cold\\|start) * p(3\\|cold)}\n",
    "    # p(3\\|cold) : emit_prob('cold', 3)\n",
    "    # sequence[0] : 3\n",
    "    for state in _states:\n",
    "        alpha[0][state] = start_prob[state] * emit_prob[state][sequence[0]]\n",
    "    \n",
    "    # sequence의 두번째 값부터 마지막까지 likelihood 모두 계산\n",
    "    # index : 위 수식에서 t\n",
    "    for index in range(1, sequence_length):\n",
    "        alpha.append({})\n",
    "        for state_to in _states:\n",
    "            prob = 0\n",
    "            for state_from in _states:\n",
    "                # += : 위 수식에서 Σ\n",
    "                # alpha[index-1] : 위 수식에서 α_t-1\n",
    "                # state_from : 위 수식에서 i\n",
    "                # state_to : 위 수식에서 j\n",
    "                # trans_prob : 위 수식에서 a_ij\n",
    "                prob += alpha[index - 1][state_from] * \\\n",
    "                    trans_prob[state_from][state_to]\n",
    "            # emit_prob : 위 수식에서 b\n",
    "            # sequence[index] : 위 수식에서 o_t \n",
    "            alpha[index][state_to] = prob * emit_prob[state_to][sequence[index]]\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'hot': 0.32000000000000006, 'cold': 0.020000000000000004}, {'hot': 0.04000000000000001, 'cold': 0.07000000000000002}, {'hot': 0.02080000000000001, 'cold': 0.005800000000000001}]\n"
     ]
    }
   ],
   "source": [
    "alpha =_forward(sequence)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _backward(sequence):\n",
    "        sequence_length = len(sequence)\n",
    "        if sequence_length == 0:\n",
    "            return []\n",
    "\n",
    "        beta = [{}]\n",
    "        for state in _states:\n",
    "            beta[0][state] = 1\n",
    "\n",
    "        for index in range(sequence_length - 1, 0, -1):\n",
    "            beta.insert(0, {})\n",
    "            for state_from in _states:\n",
    "                prob = 0\n",
    "                for state_to in _states:\n",
    "                    prob += beta[1][state_to] * \\\n",
    "                        trans_prob[state_from][state_to] * \\\n",
    "                        emit_prob[state_to][sequence[index]]\n",
    "                beta[0][state_from] = prob\n",
    "\n",
    "        return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'hot': 0.07760000000000002, 'cold': 0.0884}, {'hot': 0.28, 'cold': 0.22000000000000003}, {'hot': 1, 'cold': 1}]\n"
     ]
    }
   ],
   "source": [
    "beta = _backward(sequence)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECODE Viterbi algorithm 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(sequence):\n",
    "    # sequence : O\n",
    "    # sequence_length : T\n",
    "    sequence_length = len(sequence)\n",
    "    if sequence_length == 0:\n",
    "        return []\n",
    "    \n",
    "    # delta : 비터비 확률 v\n",
    "    # Dynamic Programming : 중간 계산값 저장해 활용\n",
    "    delta = {}\n",
    "    \n",
    "    # 시작 지점의 delta값 계산\n",
    "    for state in _states:\n",
    "        # start_prob(state) : p(cold\\|start) or p(hot\\|start)\n",
    "        # sequence[0] : 관측 시퀀스의 첫번째 요소, o_1, '3'\n",
    "        # emit_prob(state, sequence[0]) : p(3\\|cold) or p(3\\|hot)\n",
    "        delta[state] = start_prob[state] * emit_prob[state][sequence[0]]\n",
    "        \n",
    "    # pre : backtrace\n",
    "    pre = []\n",
    "    \n",
    "    # sequence의 두번째 값부터 마지막까지 delta, backtrace 모두 계산\n",
    "    # index : 위 수식에서 t\n",
    "    for index in range(1, sequence_length):\n",
    "        # delta_bar : t번째 관측치의 비터비 확률들\n",
    "        # index가 거듭될수록 그 요소가 늘어남\n",
    "        # 다 돌면 sequence_length 길이\n",
    "        delta_bar = {}\n",
    "        # pre_state : t번째 관측치의 backtrace들\n",
    "        # index가 거듭될수록 그 요소가 늘어남\n",
    "        # 다 돌면 sequence_length 길이\n",
    "        pre_state = {}\n",
    "        for state_to in _states:\n",
    "            max_prob = 0\n",
    "            max_state = None # backtrace 변수\n",
    "            for state_from in _states:\n",
    "                # state_from : 위 수식에서 i\n",
    "                # state_to : 위 수식에서 j\n",
    "                # delta[state_from] : 직전 상태의 비터비 확률(저장된 값 불러와 계산량 줄임)\n",
    "                # trans_prob : 위 수식에서 a\n",
    "                prob = delta[state_from] * trans_prob[state_from][state_to]\n",
    "                # 비터비 확률 수식에서 i에 대해 최대값을 구하는데,\n",
    "                # 방출확률 b는 i에 대해 무관하므로 최대값 연산에서 제외\n",
    "                if prob > max_prob:\n",
    "                    # 최대값 저장 : 현재 상태의 비터비 확률\n",
    "                    max_prob = prob \n",
    "                    # 최대값의 위치 저장 : 현재 상태의 backtrace\n",
    "                    max_state = state_from \n",
    "            delta_bar[state_to] = max_prob * emit_prob[state_to][sequence[index]]\n",
    "            pre_state[state_to] = max_state\n",
    "        # o_2까지의 비터비 확률을 구했다면 o_1 이전의 비터비 확률은 불필요\n",
    "        # o_2의 비터비 확률들의 모음인 delta_bar를 전체 delta에 덮어씌움\n",
    "        delta = delta_bar\n",
    "        # o_2까지의 backtrace를 구했다 하더라도 o_3은 달라질 수 있음\n",
    "        # pre에 pre_state를 append\n",
    "        pre.append(pre_state)\n",
    "    \n",
    "    # 전체 시퀀스를 대상으로 최대 비터비확률과\n",
    "    # 최대 비터비 확률을 내는 state 찾기\n",
    "    # 현재 delta에는 시퀀스의 마지막 요소(O_T)에 \n",
    "    # 해당하는 비터비 확률들이 저장돼 있기 때문\n",
    "    # (state로만 구분되어 있음)\n",
    "    max_state = None\n",
    "    max_prob = 0\n",
    "    for state in _states:\n",
    "        if delta[state] > max_prob:\n",
    "            max_prob = delta[state]\n",
    "            max_state = state\n",
    "\n",
    "    if max_state is None:\n",
    "        return []\n",
    "    \n",
    "    # 최대 비터비 확률을 내는 state가 backtrace의 첫번째 요소\n",
    "    result = [max_state]\n",
    "    # index를 시퀀스의 역방향으로 후진하면서\n",
    "    for index in range(sequence_length - 1, 0, -1):\n",
    "        # index에 해당하는 max_state들을 뽑아내기\n",
    "        # 이는 저 위쪽에서 이미 max_state들을 저장해두었기 때문에 가능\n",
    "        max_state = pre[index - 1][max_state]\n",
    "        # 뽑아낸 max_state들을 result의 첫번째 위치에 저장\n",
    "        result.insert(0, max_state)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hot', 'cold', 'hot']\n"
     ]
    }
   ],
   "source": [
    "result = decode(sequence)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
